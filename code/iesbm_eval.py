'''
@file: iesbm_eval.py
@author: qxliu
@time: 2020/5/20 19:33
'''

import argparse
from f_imp import *
from iesbm_utils import load_espo_tid

def do_eval(algo_name, fname, ds_name, topk, summtid_file_path, out_metric_dir):
	# out_metric_dir = os.path.join(OUT_DIR, 'out_%s'%algo_name, 'algo_metrics')
	# if not os.path.exists(out_metric_dir):
	# 	os.mkdir(out_metric_dir)
	out_file = os.path.join(out_metric_dir, 'FSR_{}_{}_{}.txt'.format(fname, ds_name, topk.name))
	# print('output to file:',out_file)
	fpath = None # to use default path
	feature = get_feature_by_name(fname, ds_name, fpath)
	eid_desc_dict = load_eid_desc_tids(ds_name)
	eid_fer_dict = load_eid_fer_dict(fname, ds_name, topk)

	fsr_list = []
	fer_list = []
	line_list = []
	with open(summtid_file_path, 'r', encoding='utf-8') as fin:
		for line in fin:
			items = line.strip().split('\t')
			eid = int(items[0])
			#=== 1. get escore
			summtids = eval(items[1])
			escore = feature.get_score(eid, summtids)
			#=== 2. get edesc score
			desctids = eid_desc_dict.get(eid)
			desc_score = feature.get_score(eid, desctids)
			e_fsr = escore/desc_score
			fsr_list.append(e_fsr)
			#=== 3. get ugold score
			e_fer = eid_fer_dict.get(eid)
			fer_list.append(e_fer)
			#=== for output
			line_list.append('{}\t{}\n'.format(eid, e_fsr))

	#==== compute sig
	# fer_sig_with1 = get_sig_with_1(fer_list, with_latex=False) # t, p
	fsr_sig_withfer = get_sig_two_sample_paired(fsr_list, fer_list, with_latex=False) # t, p

	#==== output
	print(fname, #ds_name, topk.name,
	      ': FSR of {}: mean={}, std={}, sigWithFER (t,p)={}'.format(algo_name, np.mean(fsr_list), np.std(fsr_list), fsr_sig_withfer))
	with open(out_file, 'w', encoding='utf-8') as fout:
		fout.writelines(line_list)

	return np.mean(fsr_list), np.std(fsr_list), fsr_sig_withfer

def fer_stats(fname, ds_name, topk): # print statistics for fer
	eid_fer_dict = load_eid_fer_dict(fname, ds_name, topk)
	fer_list = list(eid_fer_dict.values())
	fer_sig_with1 = get_sig_with_1(fer_list, with_latex=False) # t, p

	print(fname, #ds_name, topk.name,
	      'FER: mean={}, std={}, sigWith1 (t,p)={}'.format(np.mean(fer_list), np.std(fer_list), fer_sig_with1))
	return np.mean(fer_list), np.std(fer_list), fer_sig_with1

def _get_spo_from_line(ntline):
	row = ntline.strip()
	items = row.split(' ')
	s,p= items[0],items[1]
	o = row.split('>')[2].strip()
	if o.startswith('<') or '^^' in o:
		o += '>'
	if(o.endswith('.')):
		o = o[:-1].strip()
	if o.startswith('"'):
		o = o.replace('\\\"','\"')
		# o = o.replace('\"', '\\\"')
		# 	o = o.replace('\\\'','\'')
		# 	o = o.replace('\'', '\\\'')
		o = o.replace('\\\'s', '\'s')
	return s,p,o


def gen_summtid_files_from_runfile(in_algo_dir, ds_name, topk, algo_name=None):
	'''
	generate parsed files (spo to tid) for raw summary files (spo by uris), output to data/in_algo_parsed/$(algo_name)/;
	requirements:
	1. in/in_ds_parsed/$(ds_name)_tids.txt, to provide tid for spo;
	2. algosumm/@(algo_name)/$(ds_name)/, to provide raw summ files of the algo;
	output:
	file: out/out_$(algo_name)/@(ds_name)_$(topk).txt
	logged summary to tids for entities;
	:param in_algo_dir: dir of raw summary files generated by your algo
	:param ds_name: dbpedia (for ESBM-D), lmdb (for ESBM-L), dsfaces (for FED)
	:param topk:
	:param algo_name: for naming output dir
	:return:
	'''
	# ds_dir = 'dsfaces_runs' if ds_name=='dsfaces' else 'esbm_v1.2_runs'
	# in_algo_dir = os.path.join(ROOT_DIR, 'data', 'in_algo_raw', ds_dir, algo_name, ds_name)
	algo_ds_dir = os.path.join(in_algo_dir, ds_name)
	# print('algo_dir:',algo_ds_dir, os.path.exists(algo_ds_dir))
	if not os.path.exists(algo_ds_dir):
		raise Exception('input dir for algo not exist! algo_ds_dir=%s'%algo_ds_dir)
	# out_algo_dir = os.path.join(ROOT_DIR, 'data', 'in_algo_parsed',algo_name)
	out_algo_dir = os.path.join(OUT_DIR, 'out_%s'%algo_name, 'algo_parsed')
	print('output summtid to dir:',out_algo_dir)
	espo_tid_dict = load_espo_tid(ds_name)
	# conn = getConn_forDB(ds_name)
	eid_list = [x[1] for x in os.walk(algo_ds_dir)][0]
	eid_list = [int(x) for x in eid_list]
	eid_list.sort()
	# print('eid_list',eid_list)
	line_list = []
	for eid in eid_list:
		in_e_dir = os.path.join(algo_ds_dir, str(eid))
		#=== read
		summ_file_path = os.path.join(in_e_dir, '{}_{}.nt'.format(eid, topk.name))
		# summ_file_path = os.path.join(in_e_dir, '{}_desc.nt'.format(eid))# for debug
		summ_tid_list = []
		with open(summ_file_path, 'r', encoding='utf-8') as fin:
			for line in fin:
				s,p,o = _get_spo_from_line(line)
				key = (eid,s,p,o)
				tid = espo_tid_dict.get(key)
				# if eid==99:#95:#22:#99: # for debug
				# 	print('lkey:', key,'\nline:',line)
				if tid==None:
					raise Exception("wrong line! from file: %s\nline=%s\ntriple not found for eid=%d"%(summ_file_path, line,eid))
				summ_tid_list.append(tid)
		line_list.append('{}\t{}\n'.format(eid, summ_tid_list)) # one line for each entity

	out_file_path = os.path.join(out_algo_dir, '{}_{}.txt'.format(ds_name,topk.name))
	if not os.path.exists(out_algo_dir):
		os.makedirs(out_algo_dir)
	with open(out_file_path,'w',encoding='utf-8') as fout:
		fout.writelines(line_list)
	return out_file_path


def _do_print_table(table_info, ds_list, topk_list, fname_list, out_algo_dir, algo_list=None):
	key_items = [key.split('_') for key in table_info.keys()]
	fscope_list = list(set([item[0] for item in key_items])) # FER, FSR
	# ds_list = list(set([item[1] for item in key_items]))
	# topk_list = list(set([TOPK[item[2]] for item in key_items]))
	# fname_list = list(set([item[3] for item in key_items]))
	print('fscope_list:',fscope_list)

	#=== FER tables:
	if 'FER' in fscope_list:
		table_keys = topk_list
		table_leading = '============ FER of Features %s\n\t%s \n'
		table_line_list = [[table_leading%(topk.name, '\t'.join(fname_list))] for topk in topk_list] # each topk one table
		for ki, item in enumerate(table_keys):
			for ds_name in ds_list: # add row heads
				ds_label = ds_name.replace('dbpedia','ESBM-D').replace('lmdb', 'ESBM-L').replace('dsfaces', 'FED')
				table_line_list[ki].append(ds_label)
		for ki, item in enumerate(table_keys): # for each table
			topk = item
			for di, ds_name in enumerate(ds_list): # for each row
				for fname in fname_list: # one col in table
					key = 'FER_{}_{}_{}'.format(ds_name,topk.name, fname)
					fer_mean, fer_std, fer_sig = table_info.get(key)
					std_str = '(±%.3f)' % fer_std
					sig_t = fer_sig[0]
					sig_p = fer_sig[1]
					sig_str = ''
					if sig_p<0.01: # significance
						sig_str =  '↑' if sig_t>0 else '↓'
					table_line_list[ki][di + 1] += ' \t %.3f%s %s ' % (fer_mean, std_str, sig_str)  # add to row di+1
		#== table endings
		table_ending = '\n'
		for kj, item in enumerate(table_keys): # each table
			for dj, ds_name in enumerate(ds_list): # each row
				table_line_list[kj][dj+1] = '{} \n'.format(table_line_list[kj][dj+1])
			table_line_list[kj].append(table_ending)
		out_table_file = os.path.join(OUT_DIR if len(algo_list)>1 else out_algo_dir, 'result_statics_FER.txt')
		with open(out_table_file, 'w', encoding='utf-8') as fout:
			for kj, item in enumerate(table_keys):
				# fout.write('%table: {}\n'.format(item))
				fout.writelines(table_line_list[kj])

	if 'FSR' in fscope_list:
		table_leading = '============ FSR of Features %s %s \n\t %s \n'

		table_keys = [(topk, ds_name) for topk in topk_list for ds_name in ds_list]
		table_line_list = [[table_leading % (ds_name.replace('dbpedia','ESBM-D').replace('lmdb', 'ESBM-L').replace('dsfaces', 'FED')
		                                     , topk.name, '\t'.join(fname_list))] for topk in
		                   topk_list for ds_name in ds_list]  # each topk one table

		for ki, item in enumerate(table_keys):
			ds_name = item[1]
			for row_name_display in algo_list:  # add row heads (i.e. algo_name)
				table_line_list[ki].append(row_name_display)
		for ki, item in enumerate(table_keys):
			topk = item[0]
			ds_name = item[1]
			for di, row_name_display in enumerate(algo_list): # for each row
				for fname in fname_list: # one col in table
					key = 'FSR_{}_{}_{}_{}'.format(ds_name,topk.name, fname, row_name_display)
					fsr_mean, fsr_std, fsr_sig = table_info.get(key)
					# print('dddd:',fsr_mean, fsr_std, fsr_sig)
					std_str = '(±%.3f)' % fsr_std
					sig_t = fsr_sig[0]
					sig_p = fsr_sig[1]
					sig_str = ''
					if sig_p>0.01: # not significance
						sig_str =  '•'#'&#8226;' # bullet
					# table_line_list[ki][di + 1] += '<td>%.3f<small>(&#177;%.3f)</small>%s</td>' % (fsr_mean, fsr_std, sig_str)  # add to row di+1
					table_line_list[ki][di + 1] += '\t %.3f%s %s' % (fsr_mean, std_str, sig_str)  # add to row di+1

		#== table endings
		table_ending = '\n'
		for kj, item in enumerate(table_keys): # each table
			for dj, row_name_display in enumerate(algo_list): # each row
				table_line_list[kj][dj+1] = '{} \n'.format(table_line_list[kj][dj+1])
			table_line_list[kj].append(table_ending)

		out_table_file = os.path.join(OUT_DIR if len(algo_list)>1 else out_algo_dir, 'result_statics_FSR.txt')
		print('out to file:', out_table_file)
		with open(out_table_file, 'w', encoding='utf-8') as fout:
			for kj, item in enumerate(table_keys):
				# fout.write('%table: {}\n'.format(item))
				fout.writelines(table_line_list[kj])


def _do_print_table_html(table_info, ds_list, topk_list, fname_list, FSR_row_name_display_list=None):
	key_items = [key.split('_') for key in table_info.keys()]
	fscope_list = list(set([item[0] for item in key_items])) # FER, FSR
	# ds_list = list(set([item[1] for item in key_items]))
	# topk_list = list(set([TOPK[item[2]] for item in key_items]))
	# fname_list = list(set([item[3] for item in key_items]))
	print('fscope_list:',fscope_list)

	#=== FER tables:
	if 'FER' in fscope_list:
		table_keys = topk_list
		table_leading = '<strong>Table %s. FER on each dataset for k=%s.</strong>\n<table class="tablesorter" id="tb_fer_%s">\n<thead>\n<tr><th data-sorter="false" class="header"></th><th class="header">%s</th>\n</tr>\n</thead>\n<tbody>\n'
		table_line_list = [[table_leading%(str(i+1), str(topk.value), topk.name, '</th>\n<th class="header">'.join(fname_list))] for i,topk in enumerate(topk_list)] # each topk one table

		for ki, item in enumerate(table_keys):
			for ds_name in ds_list: # add row heads
				ds_label = ds_name.replace('dbpedia','ESBM-D').replace('lmdb', 'ESBM-L').replace('dsfaces', 'FED')
				table_line_list[ki].append('<tr>\n<td>{}</td>'.format(ds_label))
		for ki, item in enumerate(table_keys): # for each table
			topk = item
			for di, ds_name in enumerate(ds_list): # for each row
				for fname in fname_list: # one col in table
					key = 'FER_{}_{}_{}'.format(ds_name,topk.name, fname)
					fer_mean, fer_std, fer_sig = table_info.get(key)
					sig_t = fer_sig[0]
					sig_p = fer_sig[1]
					sig_str = ''
					if sig_p<0.01: # significance
						sig_str =  '&#8593;' if sig_t>0 else '&#8595;'
					table_line_list[ki][di + 1] += '<td>%.3f<small>(&#177;%.3f)</small>%s</td>' % (fer_mean, fer_std, sig_str)  # add to row di+1
		#== table endings
		table_ending = '</tbody></table>\n'
		for kj, item in enumerate(table_keys): # each table
			for dj, ds_name in enumerate(ds_list): # each row
				# table_line_list[kj][dj+1] = '{} \\\\\n'.format(table_line_list[kj][dj+1])
				table_line_list[kj][dj+1] = '{}</tr>\n'.format(table_line_list[kj][dj+1])
			table_line_list[kj].append(table_ending)


		out_table_file = os.path.join(OUT_DIR, 'table_forGit_FER.txt')
		with open(out_table_file, 'w', encoding='utf-8') as fout:
			for kj, item in enumerate(table_keys):
				# fout.write('%table: {}\n'.format(item))
				fout.writelines(table_line_list[kj])

	if 'FSR' in fscope_list:
		table_name = '<strong>Table %d. FSR of selected entity summarizers on %s for k=%s.</strong>'
		table_leading = table_name+ '<table class="tablesorter" id="tb_fsr_%s_%s">\n<thead>\n<tr><th data-sorter="false" class="header"></th><th class="header">%s</th>\n</tr>\n</thead>\n<tbody>\n'

		table_keys = [(topk, ds_name) for topk in topk_list for ds_name in ds_list]
		table_line_list = [[table_leading % (i+1+2
		                                     , ds_name.replace('dbpedia','ESBM-D').replace('lmdb', 'ESBM-L').replace('dsfaces', 'FED')
		                                     , str(topk.value), ds_name, topk.name, '</th>\n<th class="header">'.join(fname_list))] for i,(topk,ds_name) in enumerate(table_keys)]  # each topk one table
		for ki, item in enumerate(table_keys):
			ds_name = item[1]
			for row_name_display in FSR_row_name_display_list:  # add row heads (i.e. algo_name)
				# table_line_list[ki].append(row_name_display)
				if ds_name!='dsfaces' and row_name_display in ['FACES', 'LinkSUM']:
					table_line_list[ki].append('<!-- <tr>\n<td>{}</td>\n'.format(row_name_display))
				else:
					table_line_list[ki].append('<tr>\n<td>{}</td>\n'.format(row_name_display))
		for ki, item in enumerate(table_keys):
			topk = item[0]
			ds_name = item[1]
			for di, row_name_display in enumerate(FSR_row_name_display_list): # for each row
				for fname in fname_list: # one col in table
					key = 'FSR_{}_{}_{}_{}'.format(ds_name,topk.name, fname, row_name_display)
					fsr_mean, fsr_std, fsr_sig = table_info.get(key)
					# print('dddd:',fsr_mean, fsr_std, fsr_sig)
					sig_t = fsr_sig[0]
					sig_p = fsr_sig[1]
					sig_str = ''
					if sig_p>0.01: # not significance
						sig_str =  '&#8226;' # bullet
					table_line_list[ki][di + 1] += '<td>%.3f<small>(&#177;%.3f)</small>%s</td>' % (fsr_mean, fsr_std, sig_str)  # add to row di+1
		#== table endings
		table_ending = '</tbody></table>\n'
		for kj, item in enumerate(table_keys): # each table
			ds_name = item[1]
			for dj, row_name_display in enumerate(FSR_row_name_display_list): # each row
				# table_line_list[kj][dj+1] = '{} \\\\\n'.format(table_line_list[kj][dj+1])
				if ds_name!='dsfaces' and row_name_display in ['FACES', 'LinkSUM']:
					table_line_list[kj][dj+1] = '{}</tr> -->\n'.format(table_line_list[kj][dj+1])
				else:
					table_line_list[kj][dj+1] = '{}</tr>\n'.format(table_line_list[kj][dj+1])
			table_line_list[kj].append(table_ending)

		out_table_file = os.path.join(OUT_DIR, 'table_forGit_FSR{}.txt'.format(FSR_row_name_display_list[0] if len(FSR_row_name_display_list)==1 else ''))
		with open(out_table_file, 'w', encoding='utf-8') as fout:
			for kj, item in enumerate(table_keys):
				# fout.write('%table: {}\n'.format(item))
				fout.writelines(table_line_list[kj])

def _do_print_table_latex(table_info, ds_list, topk_list, fname_list, FSR_row_name_display_list=None):
	key_items = [key.split('_') for key in table_info.keys()]
	fscope_list = list(set([item[0] for item in key_items])) # FER, FSR
	# ds_list = list(set([item[1] for item in key_items]))
	# topk_list = list(set([TOPK[item[2]] for item in key_items]))
	# fname_list = list(set([item[3] for item in key_items]))
	print('fscope_list:',fscope_list)

	#=== FER tables:
	if 'FER' in fscope_list:
		table_keys = topk_list
		table_leading = '\\begin{table}[!t]\n\\centering\n\\caption{FER of Features %s}\n\\label{tab:fer_rmAll_%s}\n\\resizebox{\\textwidth}{!}{\n\\begin{tabular}{|l|ll|ll|l|ll|l|}\n\\hline\n & %s \\\\\n\\hline\n'
		table_line_list = [[table_leading%(topk.name, topk.name, ' & '.join(fname_list))] for topk in topk_list] # each topk one table
		for ki, item in enumerate(table_keys):
			for ds_name in ds_list: # add row heads
				ds_label = ds_name.replace('dbpedia','ESBM-D').replace('lmdb', 'ESBM-L').replace('dsfaces', 'FED')
				table_line_list[ki].append(ds_label)
		for ki, item in enumerate(table_keys): # for each table
			topk = item
			for di, ds_name in enumerate(ds_list): # for each row
				for fname in fname_list: # one col in table
					key = 'FER_{}_{}_{}'.format(ds_name,topk.name, fname)
					fer_mean, fer_std, fer_sig = table_info.get(key)
					std_str = '\\tiny{$\\pm$%.3f}' % fer_std
					sig_t = fer_sig[0]
					sig_p = fer_sig[1]
					sig_str = ''
					if sig_p<0.01: # significance
						sig_str =  '\\tiny{$^\\uparrow$}' if sig_t>0 else '\\tiny{$^\\downarrow$}'
					table_line_list[ki][di + 1] += ' & %.3f%s %s ' % (fer_mean, std_str, sig_str)  # add to row di+1
		#== table endings
		table_ending = '\\hline\n\\end{tabular}}\n\\end{table}\n'
		for kj, item in enumerate(table_keys): # each table
			for dj, ds_name in enumerate(ds_list): # each row
				table_line_list[kj][dj+1] = '{} \\\\\n'.format(table_line_list[kj][dj+1])
			table_line_list[kj].append(table_ending)
		out_table_file = os.path.join(OUT_DIR, 'table_forLatex_FER.txt')
		with open(out_table_file, 'w', encoding='utf-8') as fout:
			for kj, item in enumerate(table_keys):
				# fout.write('%table: {}\n'.format(item))
				fout.writelines(table_line_list[kj])

	if 'FSR' in fscope_list:
		table_leading = '\\begin{table}[!t]\n\\centering\n\\caption{FSR of Features %s %s}\n\\label{tab:fsr_rmAll-%s-%s}\n\\resizebox{\\textwidth}{!}{\n\\begin{tabular}{|l|ll|l|l|ll|}\n\\hline\n & %s \\\\\n\\hline\n'

		table_keys = [(topk, ds_name) for topk in topk_list for ds_name in ds_list]
		table_line_list = [[table_leading % (ds_name, topk.name, ds_name, topk.name, ' & '.join(fname_list))] for topk in
		                   topk_list for ds_name in ds_list]  # each topk one table

		for ki, item in enumerate(table_keys):
			ds_name = item[1]
			for row_name_display in FSR_row_name_display_list:  # add row heads (i.e. algo_name)
				# table_line_list[ki].append(row_name_display)
				if ds_name!='dsfaces' and row_name_display in ['FACES', 'LinkSUM']:
					table_line_list[ki].append('%'+row_name_display)
				else:
					table_line_list[ki].append(row_name_display)
		for ki, item in enumerate(table_keys):
			topk = item[0]
			ds_name = item[1]
			for di, row_name_display in enumerate(FSR_row_name_display_list): # for each row
				for fname in fname_list: # one col in table
					key = 'FSR_{}_{}_{}_{}'.format(ds_name,topk.name, fname, row_name_display)
					fsr_mean, fsr_std, fsr_sig = table_info.get(key)
					# print('dddd:',fsr_mean, fsr_std, fsr_sig)
					std_str = '\\tiny{$\\pm$%.3f}' % fsr_std
					sig_t = fsr_sig[0]
					sig_p = fsr_sig[1]
					sig_str = ''
					if sig_p>0.01: # not significance
						sig_str =  '\\tiny{$^\\bullet$}'#'&#8226;' # bullet
					# table_line_list[ki][di + 1] += '<td>%.3f<small>(&#177;%.3f)</small>%s</td>' % (fsr_mean, fsr_std, sig_str)  # add to row di+1
					table_line_list[ki][di + 1] += '& %.3f%s %s' % (fsr_mean, std_str, sig_str)  # add to row di+1

		#== table endings
		table_ending = '\\hline\n\\end{tabular}\n\\end{table}\n'
		for kj, item in enumerate(table_keys): # each table
			for dj, row_name_display in enumerate(FSR_row_name_display_list): # each row
				table_line_list[kj][dj+1] = '{} \\\\\n'.format(table_line_list[kj][dj+1])
			table_line_list[kj].append(table_ending)

		out_table_file = os.path.join(OUT_DIR, 'table_forLatex_FSR.txt')
		with open(out_table_file, 'w', encoding='utf-8') as fout:
			for kj, item in enumerate(table_keys):
				# fout.write('%table: {}\n'.format(item))
				fout.writelines(table_line_list[kj])


def print_default_tables():
	mode = 'all'
	ds_list = ['dbpedia','lmdb','dsfaces']
	topk_list = [TOPK.top5, TOPK.top10]
	fname_list = ['LFoP', 'GFoP', 'GFoV', 'IoPV', 'DoP', 'DoV']

	algo_list = [
		'relin', 'diversum', 'faces', 'faces_e', 'cd', 'linksum', 'bafrec', 'kafca', 'mpsum'
		, 'esa', 'deeplens']
	algo_display_list = [
		'RELIN', 'DIVERSUM', 'FACES', 'FACES-E', 'CD', 'LinkSUM', 'BAFREC', 'KAFCA', 'MPSUM'
		, 'ESA', 'DeepLENS']
	table_info = dict()

	dk_list = [(ds_name, topk) for topk in topk_list for ds_name in ds_list]

	# for ds_name in ds_list:
	# 	for topk in topk_list:
	for ds_name, topk in dk_list:
		for ai, algo_name in enumerate(algo_list):
			algo_dir = os.path.join(ALGOROOT_DIR, algo_name)
			print('==========================================')
			print('settings: '
			      , ds_name.replace('dbpedia','ESBM-D').replace('lmdb', 'ESBM-L').replace('dsfaces', 'FED')
			      , topk.name)
			# 1. do parse for algo
			summtid_file_path = gen_summtid_files_from_runfile(algo_dir, ds_name, topk, algo_name)
			# 2. do eval
			if mode!='FER':
				out_metric_dir = os.path.join(OUT_DIR, 'out_%s'%algo_name, 'algo_metrics')
				if not os.path.exists(out_metric_dir):
					os.mkdir(out_metric_dir)
				print('output FSR to dir: %s'%(out_metric_dir))
			for fname in fname_list:
				# 2.1 FER results
				if mode!='FSR':
					fer_results = fer_stats(fname, ds_name, topk)
					table_info['FER_{}_{}_{}'.format(ds_name,topk.name, fname)]=fer_results
				# 2.2 FSR results
				if mode!='FER':
					fsr_results = do_eval(algo_name, fname, ds_name, topk, summtid_file_path,out_metric_dir)
					table_info['FSR_{}_{}_{}_{}'.format(ds_name,topk.name, fname, algo_display_list[ai])]=fsr_results
	_do_print_table_html(table_info, ds_list, topk_list, fname_list,algo_display_list)
	_do_print_table_latex(table_info, ds_list, topk_list, fname_list,algo_display_list)



if __name__ == '__main__':
	# print_default_tables()
	parser = argparse.ArgumentParser(description='iESBM: evaluate entity summarizer')
	parser.add_argument('-mode', type=str, default='all', help="values: 'FER' for only output FER resutls; 'FSR' for only output FSR results of algorithm; 'all' for output all reasults;")
	parser.add_argument('-algo_name', type=str, help="Name of the entity summmarization algorithm to be evaluated, output files will in directory named; out_${algo_name}")
	parser.add_argument('-algodir', default=None, type=str, help='directory of the generated summaries, with sub-directory ${ds_name}/${eid}/')
	parser.add_argument('-feature_name', default=None, type=str, help="Name of the feature, values: 'LFoP', 'GFoP', 'GFoV', 'IoPV', 'DoP' and 'DoV', or customized feature.")
	parser.add_argument('-ds_name', default=None, type=str, help="Name of the dataset, values: 'dbpedia' for ESBM-D, 'lmdb' for ESBM-L, 'dsfaces' for FED.")
	parser.add_argument("-topk", default=None, type=lambda topK: TOPK[topK], help="string, 'top5' or 'top10'")
	# parser.add_argument("-print_table", default=False, type=bool, help="Whether to print table for showing the results'. If True, will generate file table_forGit_FSR.txt and table_forGit_FER.txt in data/out/")
	args = parser.parse_args()

	if args.mode not in ['all', 'FER', 'FSR']:
		raise Exception("Wrong mode! mode=%s, legal values: 'all', 'FER', 'FSR'"%args.mode)
	if args.mode!='FER' and args.algo_name==None and not args.print_table:
		raise Exception("Need param for -algo_name when mode='all' or 'FSR'!")

	algo_dir = os.path.join(ALGOROOT_DIR, args.algo_name) if args.algodir is None else args.algodir
	ds_list = ['dbpedia','lmdb','dsfaces'] if args.ds_name is None else [args.ds_name]
	topk_list = [TOPK.top5, TOPK.top10] if args.topk is None else [args.topk]
	fname_list = ['LFoP', 'GFoP', 'GFoV', 'IoPV', 'DoP', 'DoV'] if args.feature_name is None else [args.feature_name]

	if args.mode!='FER':
		out_algo_dir = os.path.join(OUT_DIR, 'out_%s'%args.algo_name)
		out_metric_dir = os.path.join(OUT_DIR, 'out_%s'%args.algo_name, 'algo_metrics')
		if not os.path.exists(out_metric_dir):
			os.makedirs(out_metric_dir)
		print('output FSR to dir: %s'%(out_metric_dir))

	table_info = dict()
	for ds_name in ds_list:
		for topk in topk_list:
			algo_dir = os.path.join(ALGOROOT_DIR, args.algo_name)
			print('==========================================')
			print('settings: '
			      , ds_name.replace('dbpedia','ESBM-D').replace('lmdb', 'ESBM-L').replace('dsfaces', 'FED')
			      , topk.name)
			# 1. do parse for algo
			summtid_file_path = gen_summtid_files_from_runfile(algo_dir, ds_name, topk, args.algo_name) if args.mode!='FER' else None
			# 2. do eval
			for fname in fname_list:
				# 2.1 FER results
				if args.mode!='FSR':
					fer_results = fer_stats(fname, ds_name, topk)
					table_info['FER_{}_{}_{}'.format(ds_name,topk.name, fname)]=fer_results
				# 2.2 FSR results
				if args.mode!='FER':
					fsr_results = do_eval(args.algo_name, fname, ds_name, topk, summtid_file_path,out_metric_dir)
					table_info['FSR_{}_{}_{}_{}'.format(ds_name,topk.name, fname, args.algo_name)]=fsr_results
	_do_print_table(table_info, ds_list, topk_list, fname_list, out_algo_dir,[args.algo_name])



